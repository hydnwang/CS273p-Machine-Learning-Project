{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "bj_xBf8gMvzP",
    "outputId": "590d2a66-c8ee-42eb-e9a2-4ff409ce55f2"
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "\n",
    "import math\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sklearn.preprocessing as preprocessing\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tl6qC4lYMvzg"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Define column names\n",
    "column_names = [\n",
    "     'age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "     'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "     'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary']\n",
    "\n",
    "# Load and split data by data_loader\n",
    "train, validation = data_loader.load_train_data('data/adult.data')\n",
    "test = data_loader.load_test_data('data/adult.test')\n",
    "\n",
    "# Combined data to consolidate features\n",
    "train['train'], train['test'] = 1, 0\n",
    "validation['train'], validation['test'] = 0, 0\n",
    "test['train'], test['test'] = 0, 1\n",
    "combined = pd.concat([train, validation, test])\n",
    "combined.columns = column_names + ['train', 'test']\n",
    "\n",
    "# Convert label to numerical binary data\n",
    "combined['salary'] = combined['salary'].replace(' <=50K.', ' <=50K')\n",
    "combined['salary'] = combined['salary'].replace(' <=50K', 0)\n",
    "combined['salary'] = combined['salary'].replace(' >50K.', ' >50K')\n",
    "combined['salary'] = combined['salary'].replace(' >50K', 1)\n",
    "\n",
    "# Clean garbage\n",
    "for c in combined.columns:\n",
    "    combined[c] = combined[c].replace(' ?', np.nan)\n",
    "combined.dropna(how='any',inplace=True)\n",
    "\n",
    "print(combined.shape)\n",
    "combined.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X\n",
    "X_combined = pd.concat([combined.iloc[:, :-3], combined.iloc[:, -2:]], axis=1)\n",
    "print(X_combined.shape)\n",
    "\n",
    "# Split Y\n",
    "Y_combined = combined.loc[:,'salary':'test']\n",
    "print(Y_combined.shape)\n",
    "Y_train = Y_combined[(Y_combined['train']==1) & (Y_combined['test']==0)].copy()\n",
    "Y_valid = Y_combined[(Y_combined['train']==0) & (Y_combined['test']==0)].copy()\n",
    "Y_test  = Y_combined[(Y_combined['train']==0) & (Y_combined['test']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distribution\n",
    "\n",
    "def plot_feature_distribution(df):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    cols = 5\n",
    "    rows = math.ceil(float(df.shape[1]) / cols)\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if column in ['salary', 'train', 'test']: continue\n",
    "        ax = fig.add_subplot(rows, cols, i + 1)\n",
    "        ax.set_title(column)\n",
    "        if df.dtypes[column] == np.object:\n",
    "            df[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "        else:\n",
    "            df[column].hist(axes=ax)\n",
    "            plt.xticks(rotation=\"vertical\")\n",
    "        plt.grid(True)\n",
    "    plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "# Plot\n",
    "plot_feature_distribution(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    for column in result.columns:\n",
    "        if column in ['train', 'test']: continue\n",
    "        if result.dtypes[column] == np.object:\n",
    "            # Fit label encoder and Transform labels to normalized encoding\n",
    "            result[column] = LabelEncoder().fit_transform(result[column])\n",
    "    return result\n",
    "\n",
    "# Numerical Encoding: feature labeling\n",
    "X_factorized = number_encode_features(X_combined)\n",
    "\n",
    "# One-hot Ecoding: feature spanning\n",
    "X_encoded = pd.get_dummies(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Data\n",
    "\n",
    "# First check ranges of each feature\n",
    "# def summerize_data(df):\n",
    "#     for column in df.columns:\n",
    "#         print(column)\n",
    "#         if df.dtypes[column] == np.object: # Categorical data\n",
    "#             print(df[column].value_counts())\n",
    "#         else:\n",
    "#             print(df[column].describe() )\n",
    "#         print('\\n')\n",
    "# summerize_data(X_factorized)\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Normalized factorized data scales\n",
    "# factorized_norm = pd.DataFrame(\n",
    "#     scaler.fit_transform(factorized.astype(float)), \n",
    "#     columns=factorized.columns\n",
    "# )\n",
    "# print(factorized_norm.shape)\n",
    "# Normalized all data scales\n",
    "# X_factorized_norm = X_factorized.copy()\n",
    "# col_names = X_factorized_norm.columns[:-2]\n",
    "# features = X_factorized_norm[col_names]\n",
    "# features = scaler.fit_transform(features.values.astype(float))\n",
    "# X_factorized_norm[col_names] = features\n",
    "\n",
    "\n",
    "# Normalized encoded data scales\n",
    "# encoded_norm = pd.DataFrame(\n",
    "#     scaler.fit_transform(encoded.astype(float)), \n",
    "#     columns=encoded.columns\n",
    "# )\n",
    "# print(encoded_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and Y with Train, Validation and Test\n",
    "\n",
    "X_train_n = X_factorized[(X_factorized['train']==1) & (X_factorized['test']==0)].copy()\n",
    "X_valid_n = X_factorized[(X_factorized['train']==0) & (X_factorized['test']==0)].copy()\n",
    "X_test_n  = X_factorized[(X_factorized['train']==0) & (X_factorized['test']==1)].copy()\n",
    "X_train_o = X_encoded[(X_encoded['train']==1) & (X_encoded['test']==0)].copy()\n",
    "X_valid_o = X_encoded[(X_encoded['train']==0) & (X_encoded['test']==0)].copy()\n",
    "X_test_o  = X_encoded[(X_encoded['train']==0) & (X_encoded['test']==1)].copy()\n",
    "\n",
    "data_map = {\n",
    "    'X_list': [\n",
    "        X_train_n, X_valid_n, X_test_n, \n",
    "        X_train_o, X_valid_o, X_test_o\n",
    "    ], \n",
    "    'Y_list': [Y_train, Y_valid, Y_test]\n",
    "}\n",
    "\n",
    "for idx, dat in data_map.items():\n",
    "    print('{}: '.format(idx), end='')\n",
    "    for d in dat:\n",
    "        if set([\"train\", \"test\"]).issubset(d.columns):\n",
    "            d.drop([\"train\", \"test\"], axis=1, inplace=True)\n",
    "        print(d.shape, end=' ')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Corellation and Importance of Data Based on Models\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "lr.fit(X_train_n, Y_train.iloc[:,0])\n",
    "coefs1 = pd.Series(lr.coef_[0], index=X_train_n.columns)\n",
    "plt.subplot(1,2,1)\n",
    "coefs1.sort_values().plot(kind=\"bar\")\n",
    "# plt.show()\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_n, Y_train.iloc[:,0])\n",
    "importance = gb.feature_importances_\n",
    "coefs2 = pd.Series(importance, index=X_train_n.columns)\n",
    "plt.subplot(1,2,2)\n",
    "coefs2.sort_values().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "# Plot using data encoded with one-hot\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "plt.figure(figsize=(20,6))\n",
    "coefs1 = pd.Series(lr.coef_[0], index=X_train_o.columns)\n",
    "coefs1.sort_values()[-20:].plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS273P - Project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
