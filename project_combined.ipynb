{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqeEUTRFoKEK"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bj_xBf8gMvzP"
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "\n",
    "import math\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sklearn.preprocessing as preprocessing\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "Tl6qC4lYMvzg",
    "outputId": "a496371f-c131-4133-8ebb-4558dbdaf3d8"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Define column names\n",
    "column_names = [\n",
    "     'age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "     'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "     'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary']\n",
    "\n",
    "# Load and split data by data_loader\n",
    "train, validation = data_loader.load_train_data('data/adult.data')\n",
    "test = data_loader.load_test_data('data/adult.test')\n",
    "\n",
    "# Combined data to consolidate features\n",
    "train['train'], train['test'] = 1, 0\n",
    "validation['train'], validation['test'] = 0, 0\n",
    "test['train'], test['test'] = 0, 1\n",
    "combined = pd.concat([train, validation, test])\n",
    "combined.columns = column_names + ['train', 'test']\n",
    "\n",
    "# Convert label to numerical binary data\n",
    "combined['salary'] = combined['salary'].replace(' <=50K.', ' <=50K')\n",
    "combined['salary'] = combined['salary'].replace(' <=50K', 0)\n",
    "combined['salary'] = combined['salary'].replace(' >50K.', ' >50K')\n",
    "combined['salary'] = combined['salary'].replace(' >50K', 1)\n",
    "\n",
    "# Clean garbage\n",
    "for c in combined.columns:\n",
    "    combined[c] = combined[c].replace(' ?', np.nan)\n",
    "combined.dropna(how='any',inplace=True)\n",
    "\n",
    "print(combined.shape)\n",
    "combined.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "YPrBwfeBoKEg",
    "outputId": "5ced214b-b4b0-42b0-e274-9326cab4b965"
   },
   "outputs": [],
   "source": [
    "# Split X\n",
    "X_combined = pd.concat([combined.iloc[:, :-3], combined.iloc[:, -2:]], axis=1)\n",
    "print(X_combined.shape)\n",
    "\n",
    "# Split Y\n",
    "Y_combined = combined.loc[:,'salary':'test']\n",
    "print(Y_combined.shape)\n",
    "Y_train = Y_combined[(Y_combined['train']==1) & (Y_combined['test']==0)].copy()\n",
    "Y_valid = Y_combined[(Y_combined['train']==0) & (Y_combined['test']==0)].copy()\n",
    "Y_test  = Y_combined[(Y_combined['train']==0) & (Y_combined['test']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 789
    },
    "colab_type": "code",
    "id": "ndYYUHlfoKEo",
    "outputId": "6a26af35-373a-4ddf-db9e-440d090d08cf"
   },
   "outputs": [],
   "source": [
    "# Plot feature distribution\n",
    "\n",
    "def plot_feature_distribution(df):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    cols = 5\n",
    "    rows = math.ceil(float(df.shape[1]) / cols)\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if column in ['salary', 'train', 'test']: continue\n",
    "        ax = fig.add_subplot(rows, cols, i + 1)\n",
    "        ax.set_title(column)\n",
    "        if df.dtypes[column] == np.object:\n",
    "            df[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "        else:\n",
    "            df[column].hist(axes=ax)\n",
    "            plt.xticks(rotation=\"vertical\")\n",
    "        plt.grid(True)\n",
    "    plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "# Plot\n",
    "plot_feature_distribution(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Modification\n",
    "FEAT_MOD = True\n",
    "\n",
    "if FEAT_MOD:\n",
    "    X_combined_m = X_combined.copy()\n",
    "    X_combined_m.loc[X_combined_m['native-country'] != ' United-States', 'native-country'] = 'Non-US'\n",
    "    X_combined_m.loc[X_combined_m['native-country'] == ' United-States', 'native-country'] = 'US'\n",
    "    X_combined_m['native-country'] = X_combined_m['native-country'].map({'US':1,'Non-US':0}).astype(int)\n",
    "\n",
    "    del X_combined_m['education-num']\n",
    "\n",
    "    print(X_combined_m.shape)\n",
    "    X_combined_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJ0ds5xNoKEu"
   },
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    for column in result.columns:\n",
    "        if column in ['train', 'test']: continue\n",
    "        if result.dtypes[column] == np.object:\n",
    "            # Fit label encoder and Transform labels to normalized encoding\n",
    "            result[column] = LabelEncoder().fit_transform(result[column])\n",
    "    return result\n",
    "\n",
    "# Numerical Encoding: feature labeling\n",
    "X_factorized = number_encode_features(X_combined)\n",
    "\n",
    "# One-hot Ecoding: feature spanning\n",
    "X_encoded = pd.get_dummies(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJ4kWAqioKEz"
   },
   "outputs": [],
   "source": [
    "# Normalizing Data\n",
    "\n",
    "# First check ranges of each feature\n",
    "# def summerize_data(df):\n",
    "#     for column in df.columns:\n",
    "#         print(column)\n",
    "#         if df.dtypes[column] == np.object: # Categorical data\n",
    "#             print(df[column].value_counts())\n",
    "#         else:\n",
    "#             print(df[column].describe() )\n",
    "#         print('\\n')\n",
    "# summerize_data(X_factorized)\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Normalized factorized data scales\n",
    "# factorized_norm = pd.DataFrame(\n",
    "#     scaler.fit_transform(factorized.astype(float)), \n",
    "#     columns=factorized.columns\n",
    "# )\n",
    "# print(factorized_norm.shape)\n",
    "# Normalized all data scales\n",
    "# X_factorized_norm = X_factorized.copy()\n",
    "# col_names = X_factorized_norm.columns[:-2]\n",
    "# features = X_factorized_norm[col_names]\n",
    "# features = scaler.fit_transform(features.values.astype(float))\n",
    "# X_factorized_norm[col_names] = features\n",
    "\n",
    "\n",
    "# Normalized encoded data scales\n",
    "# encoded_norm = pd.DataFrame(\n",
    "#     scaler.fit_transform(encoded.astype(float)), \n",
    "#     columns=encoded.columns\n",
    "# )\n",
    "# print(encoded_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RNUCUVsBoKE4",
    "outputId": "5149c207-518d-4953-b22c-1b1d1c5c5f12"
   },
   "outputs": [],
   "source": [
    "# Split data into X and Y with Train, Validation and Test\n",
    "\n",
    "X_train_n = X_factorized[(X_factorized['train']==1) & (X_factorized['test']==0)].copy()\n",
    "X_valid_n = X_factorized[(X_factorized['train']==0) & (X_factorized['test']==0)].copy()\n",
    "X_test_n  = X_factorized[(X_factorized['train']==0) & (X_factorized['test']==1)].copy()\n",
    "X_train_o = X_encoded[(X_encoded['train']==1) & (X_encoded['test']==0)].copy()\n",
    "X_valid_o = X_encoded[(X_encoded['train']==0) & (X_encoded['test']==0)].copy()\n",
    "X_test_o  = X_encoded[(X_encoded['train']==0) & (X_encoded['test']==1)].copy()\n",
    "\n",
    "X_list = [\n",
    "    X_train_n, X_valid_n, X_test_n, \n",
    "    X_train_o, X_valid_o, X_test_o\n",
    "]\n",
    "Y_list = [Y_train, Y_valid, Y_test]\n",
    "for x in X_list:\n",
    "    x.drop([\"train\", \"test\"], axis=1, inplace=True)\n",
    "    print(x.shape, end=', ')\n",
    "print('')\n",
    "    \n",
    "for y in Y_list:\n",
    "    y.drop([\"train\", \"test\"], axis=1, inplace=True)\n",
    "    print(y.shape, end=', ')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "colab_type": "code",
    "id": "z7TFfqZ_oKE-",
    "outputId": "2eb7a156-a2e4-4a17-c96f-ae4fdf1dbf44"
   },
   "outputs": [],
   "source": [
    "# Plot Correlation and Importance of Data Based on Models\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "lr.fit(X_train_n, Y_train.iloc[:,0])\n",
    "coefs1 = pd.Series(lr.coef_[0], index=X_train_n.columns)\n",
    "plt.subplot(1,2,1)\n",
    "coefs1.sort_values().plot(kind=\"bar\")\n",
    "# plt.show()\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_n, Y_train.iloc[:,0])\n",
    "importance = gb.feature_importances_\n",
    "coefs2 = pd.Series(importance, index=X_train_n.columns)\n",
    "plt.subplot(1,2,2)\n",
    "coefs2.sort_values().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "# Plot using data encoded with one-hot\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "plt.figure(figsize=(20,6))\n",
    "coefs1 = pd.Series(lr.coef_[0], index=X_train_o.columns)\n",
    "coefs1.sort_values()[-20:].plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0K936UMIoKFF"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how performance for each model is like with default setting and no parameter tuning. Also, no unimportant features removed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Predict validation data\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "v_lr_pred = lr.predict(X_valid_o)\n",
    "v_lr_probs = lr.predict_proba(X_valid_o)\n",
    "v_lr_probs = v_lr_probs[:,1]\n",
    "v_lr_acc_score = accuracy_score(Y_valid.iloc[:,0], v_lr_pred)\n",
    "v_lr_auc_score = roc_auc_score(Y_valid.iloc[:,0], v_lr_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[0], v_lr_acc_score, v_lr_auc_score))\n",
    "\n",
    "# Predict test data\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "t_lr_pred = lr.predict(X_test_o)\n",
    "t_lr_probs = lr.predict_proba(X_test_o)\n",
    "t_lr_probs = t_lr_probs[:,1]\n",
    "t_lr_acc_score = accuracy_score(Y_test.iloc[:,0], t_lr_pred)\n",
    "t_lr_auc_score = roc_auc_score(Y_test.iloc[:,0], t_lr_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC:{}\\n'.format(model_names[0], t_lr_acc_score, t_lr_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "nb = GaussianNB()\n",
    "# Predict validation data\n",
    "nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "v_nb_pred = nb.predict(X_valid_o)\n",
    "v_nb_probs = nb.predict_proba(X_valid_o)\n",
    "v_nb_probs = v_nb_probs[:,1]\n",
    "v_nb_acc_score = accuracy_score(Y_valid.iloc[:,0], v_nb_pred)\n",
    "v_nb_auc_score = roc_auc_score(Y_valid.iloc[:,0], v_nb_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[1], v_nb_acc_score, v_nb_auc_score))\n",
    "# Predict test data\n",
    "nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "t_nb_pred = nb.predict(X_test_o)\n",
    "t_nb_probs = nb.predict_proba(X_test_o)\n",
    "t_nb_probs = t_nb_probs[:,1]\n",
    "t_nb_acc_score = accuracy_score(Y_test.iloc[:,0], t_nb_pred)\n",
    "t_nb_auc_score = roc_auc_score(Y_test.iloc[:,0], t_nb_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[1], t_nb_acc_score, t_nb_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - no tuning\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Predict validation data\n",
    "gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "v_gb_pred = gb.predict(X_valid_o)\n",
    "v_gb_probs = gb.predict_proba(X_valid_o)\n",
    "v_gb_probs = v_gb_probs[:,1]\n",
    "v_gb_acc_score = accuracy_score(Y_valid.iloc[:,0], v_gb_pred)\n",
    "v_gb_auc_score = roc_auc_score(Y_valid.iloc[:,0], v_gb_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], v_gb_acc_score, v_gb_auc_score))\n",
    "\n",
    "# Predict test data\n",
    "gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "t_gb_pred = gb.predict(X_test_o)\n",
    "t_gb_probs = gb.predict_proba(X_test_o)\n",
    "t_gb_probs = t_gb_probs[:,1]\n",
    "t_gb_acc_score = accuracy_score(Y_test.iloc[:,0], t_gb_pred)\n",
    "t_gb_auc_score = roc_auc_score(Y_test.iloc[:,0], t_gb_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], t_gb_acc_score, t_gb_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - no tuning\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "# Predict validation data\n",
    "mlp.fit(X_train_o, Y_train.iloc[:,0])\n",
    "v_mlp_pred = mlp.predict(X_valid_o)\n",
    "v_mlp_probs = mlp.predict_proba(X_valid_o)\n",
    "v_mlp_probs = v_mlp_probs[:,1]\n",
    "v_mlp_acc_score = accuracy_score(Y_valid.iloc[:,0], v_mlp_pred)\n",
    "v_mlp_auc_score = roc_auc_score(Y_valid.iloc[:,0], v_mlp_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[3], v_mlp_acc_score, v_mlp_auc_score))\n",
    "# Predict test data\n",
    "mlp.fit(X_train_o, Y_train.iloc[:,0])\n",
    "t_mlp_pred = mlp.predict(X_test_o)\n",
    "t_mlp_probs = mlp.predict_proba(X_test_o)\n",
    "t_mlp_probs = t_mlp_probs[:,1]\n",
    "t_mlp_acc_score = accuracy_score(Y_test.iloc[:,0], t_mlp_pred)\n",
    "t_mlp_auc_score = roc_auc_score(Y_test.iloc[:,0], t_mlp_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[3], t_mlp_acc_score, t_mlp_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and AUC score comparison before unimportant feature remove\n",
    "print('Accuracy and AUC score comparison before unimportant feature remove\\n')\n",
    "print('Base models:\\n')\n",
    "print('Logistic Regression with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(v_lr_acc_score, v_lr_auc_score))\n",
    "print('Gaussian Naive Bayes with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(v_nb_acc_score, v_nb_auc_score))\n",
    "print('Logistic Regression with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(t_lr_acc_score, t_lr_auc_score))\n",
    "print('Gaussian Naive Bayes with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(t_nb_acc_score, t_nb_auc_score))\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "print('Advanced models:\\n')\n",
    "print('Gradient Boosting with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(v_gb_acc_score, v_gb_auc_score))\n",
    "print('Neural Network with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(v_mlp_acc_score, v_mlp_auc_score))\n",
    "print('Gradient Boosting with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(t_gb_acc_score, t_gb_auc_score))\n",
    "print('Neural Network with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(t_mlp_acc_score, t_mlp_auc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Z_bu2LmoKFH"
   },
   "source": [
    "### Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try tuning differnet parameters for each model and see which parameter(s) are better accuracy and AUC score performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Fgv4LFoKFI"
   },
   "outputs": [],
   "source": [
    "names = ['LR','GaussianNB', 'Gradient Boosting', 'Neural Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raI3f6K8oKFN",
    "outputId": "631c3f87-12a0-4b3f-b252-56100451c1e2"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "c_val = [0.01, 0.1, 1, 10, 100]\n",
    "lr_val_accu = [None]*len(c_val)\n",
    "lr_test_accu = [None]*len(c_val)\n",
    "lr_val_auc = [None]*len(c_val)\n",
    "lr_test_auc = [None]*len(c_val)\n",
    "\n",
    "for i in range(len(c_val)):\n",
    "    lr = LogisticRegression(solver='liblinear', max_iter=1000, C=c_val[i], penalty='l1')\n",
    "    print('C value: {}'.format(c_val[i]))\n",
    "    # Predict validation data\n",
    "    lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_lr_prediction = lr.predict(X_valid_o)\n",
    "    val_lr_probs = lr.predict_proba(X_valid_o)\n",
    "    val_lr_probs = val_lr_probs[:,1]\n",
    "    val_lr_acc_score = accuracy_score(Y_valid.iloc[:,0], val_lr_prediction)\n",
    "    val_lr_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_lr_probs)\n",
    "    lr_val_accu[i] = val_lr_acc_score\n",
    "    lr_val_auc[i] = val_lr_auc_score\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[0], val_lr_acc_score, val_lr_auc_score))\n",
    "    \n",
    "    # Predict test data\n",
    "    lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_lr_prediction = lr.predict(X_test_o)\n",
    "    test_lr_probs = lr.predict_proba(X_test_o)\n",
    "    test_lr_probs = test_lr_probs[:,1]\n",
    "    test_lr_acc_score = accuracy_score(Y_test.iloc[:,0], test_lr_prediction)\n",
    "    test_lr_auc_score = roc_auc_score(Y_test.iloc[:,0], test_lr_probs)\n",
    "    lr_test_accu[i] = test_lr_acc_score\n",
    "    lr_test_auc[i] = test_lr_auc_score\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[0], test_lr_acc_score, test_lr_auc_score))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2vzqzgroKFV",
    "outputId": "706b6f95-9a83-4ab1-bd08-4691f290ba1e"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression: c value accuracy and AUC plot\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Logistic Regression accuracy')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(c_val, lr_val_accu, 'b-', label='Validation')\n",
    "plt.plot(c_val, lr_test_accu, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC Score\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Logistic Regression AUC score')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(c_val, lr_val_auc, 'b-', label='Validation')\n",
    "plt.plot(c_val, lr_test_auc, 'y-', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC94a06-oKFb",
    "outputId": "a79a8704-3a6e-4ce2-d2d9-dd442baab2ee"
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "var_smooth = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "nb_val_accu = [None]*len(var_smooth)\n",
    "nb_test_accu = [None]*len(var_smooth)\n",
    "nb_val_auc = [None]*len(var_smooth)\n",
    "nb_test_auc = [None]*len(var_smooth)\n",
    "\n",
    "for i in range(len(var_smooth)):\n",
    "    nb = GaussianNB(var_smoothing=var_smooth[i])\n",
    "    print('Step value: {}'.format(var_smooth[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_nb_prediction = nb.predict(X_valid_o)\n",
    "    val_nb_probs = nb.predict_proba(X_valid_o)\n",
    "    val_nb_probs = val_nb_probs[:,1]\n",
    "    val_nb_acc_score = accuracy_score(Y_valid.iloc[:,0], val_nb_prediction)\n",
    "    val_nb_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_nb_probs)\n",
    "    nb_val_accu[i] = val_nb_acc_score\n",
    "    nb_val_auc[i] = val_nb_auc_score\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[1], val_nb_acc_score, val_nb_auc_score))\n",
    "    \n",
    "    # Predict test data\n",
    "    nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_nb_prediction = nb.predict(X_test_o)\n",
    "    test_nb_probs = nb.predict_proba(X_test_o)\n",
    "    test_nb_probs = test_nb_probs[:,1]\n",
    "    test_nb_acc_score = accuracy_score(Y_test.iloc[:,0], test_nb_prediction)\n",
    "    test_nb_auc_score = roc_auc_score(Y_test.iloc[:,0], test_nb_probs)\n",
    "    nb_test_accu[i] = test_nb_acc_score\n",
    "    nb_test_auc[i] = test_nb_auc_score\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[1], test_nb_acc_score, test_nb_auc_score))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o43Mf_k7oKFi",
    "outputId": "f9239ffc-b882-4872-dfcb-736c4c210eeb"
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes: var_smoothing accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Gaussian Naive Bayes accuracy')\n",
    "plt.xlabel('Var_smoothing value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(c_val, nb_val_accu, 'b-', label='Validation')\n",
    "plt.plot(c_val, nb_test_accu, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Gaussian Naive Bayes AUC')\n",
    "plt.xlabel('Var_smoothing value')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(c_val, nb_val_auc, 'b-', label='Validation')\n",
    "plt.plot(c_val, nb_test_auc, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_ZIebrMoKFs",
    "outputId": "82137399-be51-4862-93e0-de1ecfdf3b5b"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting - n_estimators\n",
    "stages = [50, 100, 200, 400, 800, 1600]\n",
    "gb_val_accu = [None]*len(stages)\n",
    "gb_test_accu = [None]*len(stages)\n",
    "gb_val_auc = [None]*len(stages)\n",
    "gb_test_auc = [None]*len(stages)\n",
    "\n",
    "for i in range(len(stages)):\n",
    "    gb = GradientBoostingClassifier(n_estimators=stages[i])\n",
    "    print('N_estimators: {}'.format(stages[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_gb_prediction = gb.predict(X_valid_o)\n",
    "    val_gb_probs = gb.predict_proba(X_valid_o)\n",
    "    val_gb_probs = val_gb_probs[:,1]\n",
    "    val_gb_acc_score = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction)\n",
    "    val_gb_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs)\n",
    "    gb_val_accu[i] = val_gb_acc_score\n",
    "    gb_val_auc[i] = val_gb_auc_score\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[2], val_gb_acc_score, val_gb_auc_score))\n",
    "    \n",
    "    # Predict test data\n",
    "    gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_gb_prediction = gb.predict(X_test_o)\n",
    "    test_gb_probs = gb.predict_proba(X_test_o)\n",
    "    test_gb_probs = test_gb_probs[:,1]\n",
    "    test_gb_acc_score = accuracy_score(Y_test.iloc[:,0], test_gb_prediction)\n",
    "    test_gb_auc_score = roc_auc_score(Y_test.iloc[:,0], test_gb_probs)\n",
    "    gb_test_accu[i] = test_gb_acc_score\n",
    "    gb_test_auc[i] = test_gb_auc_score\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[2], test_gb_acc_score, test_gb_auc_score))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SALWps8joKF0",
    "outputId": "56883d3e-f441-4eea-cbf8-d6693c6e4334"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting: n_estimator accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Gradient Boosting accuracy')\n",
    "plt.xlabel('N_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(stages, gb_val_accu, 'b-', label='Validation')\n",
    "plt.plot(stages, gb_test_accu, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Gradient Boosting AUC')\n",
    "plt.xlabel('N_estimators')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(stages, gb_val_auc, 'b-', label='Validation')\n",
    "plt.plot(stages, gb_test_auc, 'y-', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVwadI7noKF7",
    "outputId": "2827c77c-da22-47fe-e075-46977ed10cc8"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting - min_samples_split\n",
    "samples = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "gb_val_accu2 = [None]*len(samples)\n",
    "gb_test_accu2 = [None]*len(samples)\n",
    "gb_val_auc2 = [None]*len(samples)\n",
    "gb_test_auc2 = [None]*len(samples)\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    gb2 = GradientBoostingClassifier(min_samples_split=samples[i])\n",
    "    print('Min samples split (fraction): {}'.format(samples[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    gb2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_gb_prediction2 = gb2.predict(X_valid_o)\n",
    "    val_gb_probs2 = gb2.predict_proba(X_valid_o)\n",
    "    val_gb_probs2 = val_gb_probs2[:,1]\n",
    "    val_gb_acc_score2 = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction2)\n",
    "    val_gb_auc_score2 = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs2)\n",
    "    gb_val_accu2[i] = val_gb_acc_score2\n",
    "    gb_val_auc2[i] = val_gb_auc_score2\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[2], val_gb_acc_score2, val_gb_auc_score2))\n",
    "    \n",
    "    # Predict test data\n",
    "    gb2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_gb_prediction2 = gb2.predict(X_test_o)\n",
    "    test_gb_probs2 = gb2.predict_proba(X_test_o)\n",
    "    test_gb_probs2 = test_gb_probs2[:,1]\n",
    "    test_gb_acc_score2 = accuracy_score(Y_test.iloc[:,0], test_gb_prediction2)\n",
    "    test_gb_auc_score2 = roc_auc_score(Y_test.iloc[:,0], test_gb_probs2)\n",
    "    gb_test_accu2[i] = test_gb_acc_score2\n",
    "    gb_test_auc2[i] = test_gb_auc_score2\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[2], test_gb_acc_score2, test_gb_auc_score2))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHu5-b9LoKGC",
    "outputId": "52e1045e-f6de-46ae-8e0c-10a122c1c00c"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting: min_samples_split accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Gradient Boosting accuracy')\n",
    "plt.xlabel('Min samples split value (fraction)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(samples, gb_val_accu2, 'b-', label='Validation')\n",
    "plt.plot(samples, gb_test_accu2, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Gradient Boosting AUC')\n",
    "plt.xlabel('Min samples split value (fraction)')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(samples, gb_val_auc2, 'b-', label='Validation')\n",
    "plt.plot(samples, gb_test_auc2, 'y-', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDFImTRyovkm"
   },
   "outputs": [],
   "source": [
    "names = ['LR','GaussianNB', 'Gradient Boosting', 'Neural Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ7SHHfPoKGK",
    "outputId": "74f2098b-c11f-4584-cd41-eea930f3d31a"
   },
   "outputs": [],
   "source": [
    "# Neural Network - alpha value\n",
    "\n",
    "alpha = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "mlp_val_accu = [None]*len(alpha)\n",
    "mlp_test_accu = [None]*len(alpha)\n",
    "mlp_val_auc = [None]*len(alpha)\n",
    "mlp_test_auc = [None]*len(alpha)\n",
    "\n",
    "for i in range(len(alpha)):\n",
    "    mlp = MLPClassifier(alpha=alpha[i], max_iter=5000)\n",
    "    print('Alpha: {}'.format(alpha[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction = mlp.predict(X_valid_o)\n",
    "    val_mlp_probs = mlp.predict_proba(X_valid_o)\n",
    "    val_mlp_probs = val_mlp_probs[:,1]\n",
    "    val_mlp_acc_score = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction)\n",
    "    val_mlp_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs)\n",
    "    mlp_val_accu[i] = val_mlp_acc_score\n",
    "    mlp_val_auc[i] = val_mlp_auc_score\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score, val_mlp_auc_score))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction = mlp.predict(X_test_o)\n",
    "    test_mlp_probs = mlp.predict_proba(X_test_o)\n",
    "    test_mlp_probs = test_mlp_probs[:,1]\n",
    "    test_mlp_acc_score = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction)\n",
    "    test_mlp_auc_score = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs)\n",
    "    mlp_test_accu[i] = test_mlp_acc_score\n",
    "    mlp_test_auc[i] = test_mlp_auc_score\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score, test_mlp_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQE-dBsToKGQ",
    "outputId": "5dce83b3-1d14-4f9e-d264-5be59cb5ca6d"
   },
   "outputs": [],
   "source": [
    "# Neural Network: alpha value accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(alpha, mlp_val_accu, 'b-', label='Validation')\n",
    "plt.plot(alpha, mlp_test_accu, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(alpha, mlp_val_auc, 'b-', label='Validation')\n",
    "plt.plot(alpha, mlp_test_auc, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "Jk3nKkHQ8BH0",
    "outputId": "4cfa8683-e1cb-4482-9eec-d7c3ae328d4e"
   },
   "outputs": [],
   "source": [
    "# Neural Network - tolerance\n",
    "\n",
    "tol = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "mlp_val_accu3 = [None]*len(tol)\n",
    "mlp_test_accu3 = [None]*len(tol)\n",
    "mlp_val_auc3 = [None]*len(tol)\n",
    "mlp_test_auc3 = [None]*len(tol)\n",
    "\n",
    "for i in range(len(tol)):\n",
    "    mlp3 = MLPClassifier(tol=tol[i])\n",
    "    print('Tolerance: {}'.format(tol[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction3 = mlp3.predict(X_valid_o)\n",
    "    val_mlp_probs3 = mlp3.predict_proba(X_valid_o)\n",
    "    val_mlp_probs3 = val_mlp_probs3[:,1]\n",
    "    val_mlp_acc_score3 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction3)\n",
    "    val_mlp_auc_score3 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs3)\n",
    "    mlp_val_accu3[i] = val_mlp_acc_score3\n",
    "    mlp_val_auc3[i] = val_mlp_auc_score3\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score3, val_mlp_auc_score3))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction3 = mlp3.predict(X_test_o)\n",
    "    test_mlp_probs3 = mlp3.predict_proba(X_test_o)\n",
    "    test_mlp_probs3 = test_mlp_probs3[:,1]\n",
    "    test_mlp_acc_score3 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction3)\n",
    "    test_mlp_auc_score3 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs3)\n",
    "    mlp_test_accu3[i] = test_mlp_acc_score3\n",
    "    mlp_test_auc3[i] = test_mlp_auc_score3\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score3, test_mlp_auc_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "hPQ3UV3q8BUX",
    "outputId": "de454853-ae02-4600-ac9c-854d3ae84343"
   },
   "outputs": [],
   "source": [
    "# Neural Network: tolerance accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(tol, mlp_val_accu3, 'b-', label='Validation')\n",
    "plt.plot(tol, mlp_test_accu3, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(tol, mlp_val_auc3, 'b-', label='Validation')\n",
    "plt.plot(tol, mlp_test_auc3, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVEsXmuJfK2s"
   },
   "outputs": [],
   "source": [
    "# Neural Network - max_iter value\n",
    "\n",
    "max_iter = [200, 400, 600, 800, 1000]\n",
    "mlp_val_accu4 = [None]*len(max_iter)\n",
    "mlp_test_accu4 = [None]*len(max_iter)\n",
    "mlp_val_auc4 = [None]*len(max_iter)\n",
    "mlp_test_auc4 = [None]*len(max_iter)\n",
    "\n",
    "for i in range(len(max_iter)):\n",
    "    mlp4 = MLPClassifier(max_iter=max_iter[i])\n",
    "    print('max_iter: {}'.format(max_iter[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction4 = mlp4.predict(X_valid_o)\n",
    "    val_mlp_probs4 = mlp4.predict_proba(X_valid_o)\n",
    "    val_mlp_probs4 = val_mlp_probs4[:,1]\n",
    "    val_mlp_acc_score4 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction4)\n",
    "    val_mlp_auc_score4 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs4)\n",
    "    mlp_val_accu4[i] = val_mlp_acc_score4\n",
    "    mlp_val_auc4[i] = val_mlp_auc_score4\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score4, val_mlp_auc_score4))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction4 = mlp4.predict(X_test_o)\n",
    "    test_mlp_probs4 = mlp4.predict_proba(X_test_o)\n",
    "    test_mlp_probs4 = test_mlp_probs4[:,1]\n",
    "    test_mlp_acc_score4 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction4)\n",
    "    test_mlp_auc_score4 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs4)\n",
    "    mlp_test_accu4[i] = test_mlp_acc_score4\n",
    "    mlp_test_auc4[i] = test_mlp_auc_score4\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score4, test_mlp_auc_score4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "b3ZrS9VYL5Rg",
    "outputId": "f410958a-b16d-40a9-9f65-f853f5732f82"
   },
   "outputs": [],
   "source": [
    "# Neural Network: max_iter accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Max iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_iter, mlp_val_accu4, 'b-', label='Validation')\n",
    "plt.plot(max_iter, mlp_test_accu4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Max iterations')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(max_iter, mlp_val_auc4, 'b-', label='Validation')\n",
    "plt.plot(max_iter, mlp_test_auc4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "dHHeGfSsL5WA",
    "outputId": "23b3c706-9e53-4394-8106-fe9780a4e378"
   },
   "outputs": [],
   "source": [
    "# Neural Network - batch_size value\n",
    "\n",
    "batch_size = [200, 300, 400, 500, 600]\n",
    "mlp_val_accu5 = [None]*len(batch_size)\n",
    "mlp_test_accu5 = [None]*len(batch_size)\n",
    "mlp_val_auc5 = [None]*len(batch_size)\n",
    "mlp_test_auc5 = [None]*len(batch_size)\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    mlp5 = MLPClassifier(batch_size=batch_size[i])\n",
    "    print('Batch size: {}'.format(batch_size[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp5.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction5 = mlp5.predict(X_valid_o)\n",
    "    val_mlp_probs5 = mlp5.predict_proba(X_valid_o)\n",
    "    val_mlp_probs5 = val_mlp_probs5[:,1]\n",
    "    val_mlp_acc_score5 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction5)\n",
    "    val_mlp_auc_score5 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs5)\n",
    "    mlp_val_accu5[i] = val_mlp_acc_score5\n",
    "    mlp_val_auc5[i] = val_mlp_auc_score5\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score5, val_mlp_auc_score5))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp5.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction5 = mlp5.predict(X_test_o)\n",
    "    test_mlp_probs5 = mlp5.predict_proba(X_test_o)\n",
    "    test_mlp_probs5 = test_mlp_probs5[:,1]\n",
    "    test_mlp_acc_score5 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction5)\n",
    "    test_mlp_auc_score5 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs5)\n",
    "    mlp_test_accu5[i] = test_mlp_acc_score5\n",
    "    mlp_test_auc5[i] = test_mlp_auc_score5\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score5, test_mlp_auc_score5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "hNRxoVG7L5Zs",
    "outputId": "2613c75b-ad86-4261-e115-47d4926e5972"
   },
   "outputs": [],
   "source": [
    "# Neural Network: batch_size accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(batch_size, mlp_val_accu5, 'b-', label='Validation')\n",
    "plt.plot(batch_size, mlp_test_accu5, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(batch_size, mlp_val_auc5, 'b-', label='Validation')\n",
    "plt.plot(batch_size, mlp_test_auc5, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "Vg46PvkHUnOL",
    "outputId": "4f353225-fe2e-4e8d-bb4d-bc2c9e89a52c"
   },
   "outputs": [],
   "source": [
    "# Neural Network - momentum\n",
    "\n",
    "m = [0.91, 0.93, 0.95, 0.97, 0.99]\n",
    "mlp_val_accu6 = [None]*len(m)\n",
    "mlp_test_accu6 = [None]*len(m)\n",
    "mlp_val_auc6 = [None]*len(m)\n",
    "mlp_test_auc6 = [None]*len(m)\n",
    "\n",
    "for i in range(len(m)):\n",
    "    mlp6 = MLPClassifier(momentum=m[i])\n",
    "    print('Momentum: {}'.format(m[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp6.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction6 = mlp6.predict(X_valid_o)\n",
    "    val_mlp_probs6 = mlp6.predict_proba(X_valid_o)\n",
    "    val_mlp_probs6 = val_mlp_probs6[:,1]\n",
    "    val_mlp_acc_score6 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction6)\n",
    "    val_mlp_auc_score6 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs6)\n",
    "    mlp_val_accu6[i] = val_mlp_acc_score6\n",
    "    mlp_val_auc6[i] = val_mlp_auc_score6\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score6, val_mlp_auc_score6))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp6.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction6 = mlp6.predict(X_test_o)\n",
    "    test_mlp_probs6 = mlp6.predict_proba(X_test_o)\n",
    "    test_mlp_probs6 = test_mlp_probs6[:,1]\n",
    "    test_mlp_acc_score6 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction5)\n",
    "    test_mlp_auc_score6 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs5)\n",
    "    mlp_test_accu6[i] = test_mlp_acc_score6\n",
    "    mlp_test_auc6[i] = test_mlp_auc_score6\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score5, test_mlp_auc_score5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "KYtMVK3rUnW0",
    "outputId": "517ad9c1-a03e-4e97-fb1d-2aa5bdc6ec3e"
   },
   "outputs": [],
   "source": [
    "# Neural Network: momemtum accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Momentum')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(m, mlp_val_accu6, 'b-', label='Validation')\n",
    "plt.plot(m, mlp_test_accu6, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Momentum')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(m, mlp_val_auc6, 'b-', label='Validation')\n",
    "plt.plot(m, mlp_test_auc6, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unimportant features and retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the base models and advanced models to see their performances after removing unimportant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['LR','GaussianNB','Gradient Boosting', 'Neural Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Predict validation data\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_lr_prediction = lr.predict(X_valid_o)\n",
    "val_lr_probs = lr.predict_proba(X_valid_o)\n",
    "val_lr_probs = val_lr_probs[:,1]\n",
    "val_lr_acc_score = accuracy_score(Y_valid.iloc[:,0], val_lr_prediction)\n",
    "val_lr_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_lr_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[0], val_lr_acc_score, val_lr_auc_score))\n",
    "\n",
    "# Predict test data\n",
    "lr.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_lr_prediction = lr.predict(X_test_o)\n",
    "test_lr_probs = lr.predict_proba(X_test_o)\n",
    "test_lr_probs = test_lr_probs[:,1]\n",
    "test_lr_acc_score = accuracy_score(Y_test.iloc[:,0], test_lr_prediction)\n",
    "test_lr_auc_score = roc_auc_score(Y_test.iloc[:,0], test_lr_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC:{}\\n'.format(model_names[0], test_lr_acc_score, test_lr_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "nb = GaussianNB()\n",
    "# Predict validation data\n",
    "nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_nb_prediction = nb.predict(X_valid_o)\n",
    "val_nb_probs = nb.predict_proba(X_valid_o)\n",
    "val_nb_probs = val_nb_probs[:,1]\n",
    "val_nb_acc_score = accuracy_score(Y_valid.iloc[:,0], val_nb_prediction)\n",
    "val_nb_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_nb_probs)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[1], val_nb_acc_score, val_nb_auc_score))\n",
    "# Predict test data\n",
    "nb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_nb_prediction = nb.predict(X_test_o)\n",
    "test_nb_probs = nb.predict_proba(X_test_o)\n",
    "test_nb_probs = test_nb_probs[:,1]\n",
    "test_nb_acc_score = accuracy_score(Y_test.iloc[:,0], test_nb_prediction)\n",
    "test_nb_auc_score = roc_auc_score(Y_test.iloc[:,0], test_nb_probs)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[1], test_nb_acc_score, test_nb_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - n_estimators\n",
    "stages = [50, 100, 200, 400, 800, 1600]\n",
    "gb_val_accu = [None]*len(stages)\n",
    "gb_test_accu = [None]*len(stages)\n",
    "gb_val_auc = [None]*len(stages)\n",
    "gb_test_auc = [None]*len(stages)\n",
    "\n",
    "for i in range(len(stages)):\n",
    "    gb = GradientBoostingClassifier(n_estimators=stages[i])\n",
    "    print('N_estimators: {}'.format(stages[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_gb_prediction = gb.predict(X_valid_o)\n",
    "    val_gb_probs = gb.predict_proba(X_valid_o)\n",
    "    val_gb_probs = val_gb_probs[:,1]\n",
    "    val_gb_acc_score = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction)\n",
    "    val_gb_auc_score = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs)\n",
    "    gb_val_accu[i] = val_gb_acc_score\n",
    "    gb_val_auc[i] = val_gb_auc_score\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], val_gb_acc_score, val_gb_auc_score))\n",
    "    \n",
    "    # Predict test data\n",
    "    gb.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_gb_prediction = gb.predict(X_test_o)\n",
    "    test_gb_probs = gb.predict_proba(X_test_o)\n",
    "    test_gb_probs = test_gb_probs[:,1]\n",
    "    test_gb_acc_score = accuracy_score(Y_test.iloc[:,0], test_gb_prediction)\n",
    "    test_gb_auc_score = roc_auc_score(Y_test.iloc[:,0], test_gb_probs)\n",
    "    gb_test_accu[i] = test_gb_acc_score\n",
    "    gb_test_auc[i] = test_gb_auc_score\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[2], test_gb_acc_score, test_gb_auc_score))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting: n_estimator accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Gradient Boosting accuracy')\n",
    "plt.xlabel('N_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(stages, gb_val_accu, 'b-', label='Validation')\n",
    "plt.plot(stages, gb_test_accu, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Gradient Boosting AUC')\n",
    "plt.xlabel('N_estimators')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(stages, gb_val_auc, 'b-', label='Validation')\n",
    "plt.plot(stages, gb_test_auc, 'y-', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - learning rate\n",
    "learn = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "gb_val_accu4 = [None]*len(learn)\n",
    "gb_test_accu4 = [None]*len(learn)\n",
    "gb_val_auc4 = [None]*len(learn)\n",
    "gb_test_auc4 = [None]*len(learn)\n",
    "\n",
    "for i in range(len(learn)):\n",
    "    gb4 = GradientBoostingClassifier(learning_rate=learn[i])\n",
    "    print('Learning rate: {}'.format(learn[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    gb4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_gb_prediction4 = gb4.predict(X_valid_o)\n",
    "    val_gb_probs4 = gb4.predict_proba(X_valid_o)\n",
    "    val_gb_probs4 = val_gb_probs4[:,1]\n",
    "    val_gb_acc_score4 = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction4)\n",
    "    val_gb_auc_score4 = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs4)\n",
    "    gb_val_accu4[i] = val_gb_acc_score4\n",
    "    gb_val_auc4[i] = val_gb_auc_score4\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], val_gb_acc_score4, val_gb_auc_score4))\n",
    "    \n",
    "    # Predict test data\n",
    "    gb4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_gb_prediction4 = gb4.predict(X_test_o)\n",
    "    test_gb_probs4 = gb4.predict_proba(X_test_o)\n",
    "    test_gb_probs4 = test_gb_probs4[:,1]\n",
    "    test_gb_acc_score4 = accuracy_score(Y_test.iloc[:,0], test_gb_prediction4)\n",
    "    test_gb_auc_score4 = roc_auc_score(Y_test.iloc[:,0], test_gb_probs4)\n",
    "    gb_test_accu4[i] = test_gb_acc_score4\n",
    "    gb_test_auc4[i] = test_gb_auc_score4\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[2], test_gb_acc_score4, test_gb_auc_score4))\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting: learning rate accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Gradient Boosting accuracy')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(learn, gb_val_accu4, 'b-', label='Validation')\n",
    "plt.plot(learn, gb_test_accu4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Gradient Boosting AUC')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(learn, gb_val_auc4, 'b-', label='Validation')\n",
    "plt.plot(learn, gb_test_auc4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - max_iter value\n",
    "\n",
    "max_iter = [200, 400, 600, 800, 1000]\n",
    "mlp_val_accu4 = [None]*len(max_iter)\n",
    "mlp_test_accu4 = [None]*len(max_iter)\n",
    "mlp_val_auc4 = [None]*len(max_iter)\n",
    "mlp_test_auc4 = [None]*len(max_iter)\n",
    "\n",
    "for i in range(len(max_iter)):\n",
    "    mlp4 = MLPClassifier(max_iter=max_iter[i])\n",
    "    print('max_iter: {}'.format(max_iter[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction4 = mlp4.predict(X_valid_o)\n",
    "    val_mlp_probs4 = mlp4.predict_proba(X_valid_o)\n",
    "    val_mlp_probs4 = val_mlp_probs4[:,1]\n",
    "    val_mlp_acc_score4 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction4)\n",
    "    val_mlp_auc_score4 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs4)\n",
    "    mlp_val_accu4[i] = val_mlp_acc_score4\n",
    "    mlp_val_auc4[i] = val_mlp_auc_score4\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score4, val_mlp_auc_score4))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp4.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction4 = mlp4.predict(X_test_o)\n",
    "    test_mlp_probs4 = mlp4.predict_proba(X_test_o)\n",
    "    test_mlp_probs4 = test_mlp_probs4[:,1]\n",
    "    test_mlp_acc_score4 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction4)\n",
    "    test_mlp_auc_score4 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs4)\n",
    "    mlp_test_accu4[i] = test_mlp_acc_score4\n",
    "    mlp_test_auc4[i] = test_mlp_auc_score4\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score4, test_mlp_auc_score4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network: max_iter accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Max iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_iter, mlp_val_accu4, 'b-', label='Validation')\n",
    "plt.plot(max_iter, mlp_test_accu4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Max iterations')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(max_iter, mlp_val_auc4, 'b-', label='Validation')\n",
    "plt.plot(max_iter, mlp_test_auc4, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - tolerance\n",
    "\n",
    "tol = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "mlp_val_accu3 = [None]*len(tol)\n",
    "mlp_test_accu3 = [None]*len(tol)\n",
    "mlp_val_auc3 = [None]*len(tol)\n",
    "mlp_test_auc3 = [None]*len(tol)\n",
    "\n",
    "for i in range(len(tol)):\n",
    "    mlp3 = MLPClassifier(tol=tol[i])\n",
    "    print('Tolerance: {}'.format(tol[i]))\n",
    "    \n",
    "    # Predict validation data\n",
    "    mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    val_mlp_prediction3 = mlp3.predict(X_valid_o)\n",
    "    val_mlp_probs3 = mlp3.predict_proba(X_valid_o)\n",
    "    val_mlp_probs3 = val_mlp_probs3[:,1]\n",
    "    val_mlp_acc_score3 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction3)\n",
    "    val_mlp_auc_score3 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs3)\n",
    "    mlp_val_accu3[i] = val_mlp_acc_score3\n",
    "    mlp_val_auc3[i] = val_mlp_auc_score3\n",
    "    print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(names[3], val_mlp_acc_score3, val_mlp_auc_score3))\n",
    "    \n",
    "    # Predict test data\n",
    "    mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "    test_mlp_prediction3 = mlp3.predict(X_test_o)\n",
    "    test_mlp_probs3 = mlp3.predict_proba(X_test_o)\n",
    "    test_mlp_probs3 = test_mlp_probs3[:,1]\n",
    "    test_mlp_acc_score3 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction3)\n",
    "    test_mlp_auc_score3 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs3)\n",
    "    mlp_test_accu3[i] = test_mlp_acc_score3\n",
    "    mlp_test_auc3[i] = test_mlp_auc_score3\n",
    "    print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(names[3], test_mlp_acc_score3, test_mlp_auc_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network: tolerance accuracy and AUC plot\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('MLPClassifer accuracy')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(tol, mlp_val_accu3, 'b-', label='Validation')\n",
    "plt.plot(tol, mlp_test_accu3, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('MLPClassifer AUC')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('AUC score')\n",
    "plt.plot(tol, mlp_val_auc3, 'b-', label='Validation')\n",
    "plt.plot(tol, mlp_test_auc3, 'y-', label='Test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the performance of each model after removing unimportant feature. In the comparison, the base models uses default parameter settings and the advanced models have the best parameter tuned due to previous experience from running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - no tuning\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "\n",
    "# Predict validation data\n",
    "gb1.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_gb_prediction1 = gb1.predict(X_valid_o)\n",
    "val_gb_probs1 = gb1.predict_proba(X_valid_o)\n",
    "val_gb_probs1 = val_gb_probs1[:,1]\n",
    "val_gb_acc_score1 = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction1)\n",
    "val_gb_auc_score1 = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs1)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], val_gb_acc_score1, val_gb_auc_score1))\n",
    "\n",
    "# Predict test data\n",
    "gb1.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_gb_prediction1 = gb1.predict(X_test_o)\n",
    "test_gb_probs1 = gb1.predict_proba(X_test_o)\n",
    "test_gb_probs1 = test_gb_probs1[:,1]\n",
    "test_gb_acc_score1 = accuracy_score(Y_test.iloc[:,0], test_gb_prediction1)\n",
    "test_gb_auc_score1 = roc_auc_score(Y_test.iloc[:,0], test_gb_probs1)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], test_gb_acc_score1, test_gb_auc_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - with best n_estimators\n",
    "\n",
    "gb2 = GradientBoostingClassifier(n_estimators=800)\n",
    "\n",
    "# Predict validation data\n",
    "gb2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_gb_prediction2 = gb2.predict(X_valid_o)\n",
    "val_gb_probs2 = gb2.predict_proba(X_valid_o)\n",
    "val_gb_probs2 = val_gb_probs2[:,1]\n",
    "val_gb_acc_score2 = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction2)\n",
    "val_gb_auc_score2 = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs2)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], val_gb_acc_score2, val_gb_auc_score2))\n",
    "\n",
    "# Predict test data\n",
    "gb2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_gb_prediction2 = gb2.predict(X_test_o)\n",
    "test_gb_probs2 = gb2.predict_proba(X_test_o)\n",
    "test_gb_probs2 = test_gb_probs2[:,1]\n",
    "test_gb_acc_score2 = accuracy_score(Y_test.iloc[:,0], test_gb_prediction2)\n",
    "test_gb_auc_score2 = roc_auc_score(Y_test.iloc[:,0], test_gb_probs2)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], test_gb_acc_score2, test_gb_auc_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting - with best learning rate\n",
    "\n",
    "gb3 = GradientBoostingClassifier(learning_rate=0.3)\n",
    "\n",
    "# Predict validation data\n",
    "gb3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_gb_prediction3 = gb3.predict(X_valid_o)\n",
    "val_gb_probs3 = gb3.predict_proba(X_valid_o)\n",
    "val_gb_probs3 = val_gb_probs3[:,1]\n",
    "val_gb_acc_score3 = accuracy_score(Y_valid.iloc[:,0], val_gb_prediction3)\n",
    "val_gb_auc_score3 = roc_auc_score(Y_valid.iloc[:,0], val_gb_probs3)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], val_gb_acc_score3, val_gb_auc_score3))\n",
    "\n",
    "# Predict test data\n",
    "gb3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_gb_prediction3 = gb3.predict(X_test_o)\n",
    "test_gb_probs3 = gb3.predict_proba(X_test_o)\n",
    "test_gb_probs3 = test_gb_probs3[:,1]\n",
    "test_gb_acc_score3 = accuracy_score(Y_test.iloc[:,0], test_gb_prediction3)\n",
    "test_gb_auc_score3 = roc_auc_score(Y_test.iloc[:,0], test_gb_probs3)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[2], test_gb_acc_score3, test_gb_auc_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - no tuning\n",
    "\n",
    "mlp1 = MLPClassifier()\n",
    "# Predict validation data\n",
    "mlp1.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_mlp_prediction1 = mlp1.predict(X_valid_o)\n",
    "val_mlp_probs1 = mlp1.predict_proba(X_valid_o)\n",
    "val_mlp_probs1 = val_mlp_probs1[:,1]\n",
    "val_mlp_acc_score1 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction1)\n",
    "val_mlp_auc_score1 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs1)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[3], val_mlp_acc_score1, val_mlp_auc_score1))\n",
    "# Predict test data\n",
    "mlp1.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_mlp_prediction1 = mlp1.predict(X_test_o)\n",
    "test_mlp_probs1 = mlp1.predict_proba(X_test_o)\n",
    "test_mlp_probs1 = test_mlp_probs1[:,1]\n",
    "test_mlp_acc_score1 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction1)\n",
    "test_mlp_auc_score1 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs1)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[3], test_mlp_acc_score1, test_mlp_auc_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - with best tolerance\n",
    "\n",
    "mlp2 = MLPClassifier(tol=0.001)\n",
    "# Predict validation data\n",
    "mlp2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_mlp_prediction2 = mlp2.predict(X_valid_o)\n",
    "val_mlp_probs2 = mlp2.predict_proba(X_valid_o)\n",
    "val_mlp_probs2 = val_mlp_probs2[:,1]\n",
    "val_mlp_acc_score2 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction2)\n",
    "val_mlp_auc_score2 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs2)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[3], val_mlp_acc_score2, val_mlp_auc_score2))\n",
    "# Predict test data\n",
    "mlp2.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_mlp_prediction2 = mlp2.predict(X_test_o)\n",
    "test_mlp_probs2 = mlp2.predict_proba(X_test_o)\n",
    "test_mlp_probs2 = test_mlp_probs2[:,1]\n",
    "test_mlp_acc_score2 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction2)\n",
    "test_mlp_auc_score2 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs2)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[3], test_mlp_acc_score2, test_mlp_auc_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - with best max_iter\n",
    "\n",
    "mlp3 = MLPClassifier(max_iter=1000)\n",
    "# Predict validation data\n",
    "mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "val_mlp_prediction3 = mlp3.predict(X_valid_o)\n",
    "val_mlp_probs3 = mlp3.predict_proba(X_valid_o)\n",
    "val_mlp_probs3 = val_mlp_probs3[:,1]\n",
    "val_mlp_acc_score3 = accuracy_score(Y_valid.iloc[:,0], val_mlp_prediction3)\n",
    "val_mlp_auc_score3 = roc_auc_score(Y_valid.iloc[:,0], val_mlp_probs3)\n",
    "print('Validation - Model: {}, Accuracy: {}, AUC: {}'.format(model_names[3], val_mlp_acc_score3, val_mlp_auc_score3))\n",
    "# Predict test data\n",
    "mlp3.fit(X_train_o, Y_train.iloc[:,0])\n",
    "test_mlp_prediction3 = mlp3.predict(X_test_o)\n",
    "test_mlp_probs3 = mlp3.predict_proba(X_test_o)\n",
    "test_mlp_probs3 = test_mlp_probs3[:,1]\n",
    "test_mlp_acc_score3 = accuracy_score(Y_test.iloc[:,0], test_mlp_prediction3)\n",
    "test_mlp_auc_score3 = roc_auc_score(Y_test.iloc[:,0], test_mlp_probs3)\n",
    "print('Test - Model: {}, Accuracy: {}, AUC: {}\\n'.format(model_names[3], test_mlp_acc_score3, test_mlp_auc_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and AUC score comparison after unimportant feature remove\n",
    "print('Accuracy and AUC score comparison after unimportant feature remove\\n')\n",
    "print('Base models:\\n')\n",
    "print('Logistic Regression with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_lr_acc_score, val_lr_auc_score))\n",
    "print('Gaussian Naive Bayes with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_nb_acc_score, val_nb_auc_score))\n",
    "print('\\n---------------------\\n')\n",
    "print('Logistic Regression with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_lr_acc_score, test_lr_auc_score))\n",
    "print('Gaussian Naive Bayes with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_nb_acc_score, test_nb_auc_score))\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "print('Advanced models:\\n')\n",
    "print('Gradient Boosting with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_gb_acc_score1, val_gb_auc_score1))\n",
    "print('Gradient Boosting with n_estimator (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_gb_acc_score2, val_gb_auc_score2))\n",
    "print('Gradient Boosting with learning rate (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_gb_acc_score3, val_gb_auc_score3))\n",
    "print('\\n')\n",
    "print('Neural Network with no tuning (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_mlp_acc_score1, val_mlp_auc_score1))\n",
    "print('Neural Network with tolerance (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_mlp_acc_score2, val_mlp_auc_score2))\n",
    "print('Neural Network with max_iter (Validation) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(val_mlp_acc_score3, val_mlp_auc_score3))\n",
    "print('\\n---------------------\\n')\n",
    "print('Gradient Boosting with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_gb_acc_score1, test_gb_auc_score1))\n",
    "print('Gradient Boosting with n_estimator (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_gb_acc_score2, test_gb_auc_score2))\n",
    "print('Gradient Boosting with learning rate (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_gb_acc_score3, test_gb_auc_score3))                                                                           \n",
    "print('\\n')\n",
    "print('Neural Network with no tuning (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_mlp_acc_score1, test_mlp_auc_score1))\n",
    "print('Neural Network with tolerance (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_mlp_acc_score2, test_mlp_auc_score2))\n",
    "print('Neural Network with max_iter (Test) - Accuracy: {:2.5f}, AUC: {:2.5f}'.format(test_mlp_acc_score3, test_mlp_auc_score3))                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
